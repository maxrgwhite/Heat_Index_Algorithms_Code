{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this code will compare 21 heat index algorithms from Anderson et al (2013) to Lu and Romps (2022)\n",
    "If using hourly-level data, expect considerable waiting times (8+ hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Step_5_Data_Analysis_backend.ipynb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.analysis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tas: temperature at surface (in ˚C)\n",
    "# rh: relative humidity (in %)\n",
    "# td: dew point temperature (in ˚C)\n",
    "# es: water vapor pressure (in kilopascals)\n",
    "\n",
    "# Heat Index 22 is the Lu and Romps heat index cube\n",
    "\n",
    "location_name = 'Limpopo'\n",
    "start_year = 1950\n",
    "end_year = 2024\n",
    "\n",
    "# Specify an output folder for figures\n",
    "output_folder = f'{os.getcwd()}/{location_name}_outputs'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "unprocessed_output_folder = f'{output_folder}/basic_plots_for_unprocessed_data'\n",
    "if not os.path.exists(unprocessed_output_folder):\n",
    "    os.makedirs(unprocessed_output_folder)\n",
    "\n",
    "# Specify shapefile to work with\n",
    "shapefile = gpd.read_file('/Users/maxwhite/Documents/Met_Office_Work/Heat_index_Algorithms/Data/Limpopo/Limpopo_Boundaries.geojson')\n",
    "\n",
    "heat_indeces_cubelist, tas_cube, rh_cube, td_cube, es_cube = load_my_files()\n",
    "\n",
    "# Add day of year coordinate to cubes if it doesn't already exist\n",
    "for cube in heat_indeces_cubelist:\n",
    "    try:\n",
    "        cube.coord('day_of_year')\n",
    "    except iris.exceptions.CoordinateNotFoundError:\n",
    "        iris.coord_categorisation.add_day_of_year(cube, 'time', name='day_of_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dimenions_to_my_cubes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A TEMPORARY SUBSET\n",
    "heat_indeces_cubelist_subset = iris.cube.CubeList([])\n",
    "for cube in heat_indeces_cubelist:\n",
    "    cube_subset = cube.extract(iris.Constraint(time=lambda cell: 2020 <= cell.point.year <= 2022))\n",
    "    heat_indeces_cubelist_subset.append(cube_subset)\n",
    "\n",
    "heat_indeces_cubelist = heat_indeces_cubelist_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yearly_aggregates() # Creates season year aggregates of the tas, rh, td, and es cubes\n",
    "create_overall_aggregates() # Creates mappable aggregates of the tas, rh, td, and es cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_cubes_for_time_series() # Spatially collapses the cubes for time series analysis\n",
    "collapse_cubes_for_maps() # Temporally collapses the cubes for map analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_air_temperature_for_time_series() # Collapses the air temperature cube for time series analysis to allow comparison\n",
    "collapse_air_temperature_for_maps() # Collapses the air temperature cube for map analysis to allow comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic descriptive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_my_region() # Plots the region specified by the shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_yearly_average_tas_and_rh() # Plots the yearly mean, min, and max values of tas, rh, td, and es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly_average_tas_and_rh() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hourly_average_tas_and_rh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min_mean_max_analysis_maps() # Plots the mean analysis maps for tas, rh, td, and es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_summary_statistics() # Writes summary statistics to a csv file (mean, min, max, std, variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Comparing the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating masked versions of the cube, containing only data ≥ 298 for computational efficiency of below tasks\n",
    "masked_hourly_data_cubelist = heat_indeces_cubelist.copy()\n",
    "for cube in masked_hourly_data_cubelist:\n",
    "    cube.data = np.ma.masked_where(cube.data < 298, cube.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds\n",
    "thresholds = [298, 345, 357, 366]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "hourly_counts_per_threshold_df = pd.DataFrame(columns=['Algorithm'] + [f'Count_{threshold}' for threshold in thresholds])\n",
    "\n",
    "hourly_counts_per_threshold_df['Algorithm'] = [cube.long_name for cube in masked_hourly_data_cubelist]\n",
    "hourly_counts_per_threshold_df\n",
    "\n",
    "for i, cube in enumerate(masked_hourly_data_cubelist):\n",
    "    count_above_298 = (cube.data >= 298).sum()\n",
    "    hourly_counts_per_threshold_df.loc[i, 'Count_298'] = count_above_298\n",
    "\n",
    "for i, cube in enumerate(masked_hourly_data_cubelist):\n",
    "    count_above_345 = (cube.data >= 345).sum()\n",
    "    hourly_counts_per_threshold_df.loc[i, 'Count_345'] = count_above_345\n",
    "\n",
    "for i, cube in enumerate(masked_hourly_data_cubelist):\n",
    "    count_above_357 = (cube.data >= 357).sum()\n",
    "    hourly_counts_per_threshold_df.loc[i, 'Count_357'] = count_above_357\n",
    "\n",
    "for i, cube in enumerate(masked_hourly_data_cubelist):\n",
    "    count_above_366 = (cube.data >= 366).sum()\n",
    "    hourly_counts_per_threshold_df.loc[i, 'Count_366'] = count_above_366\n",
    "\n",
    "print(hourly_counts_per_threshold_df)\n",
    "hourly_counts_per_threshold_df.to_csv(f'{output_folder}/hourly_counts_per_threshold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the positions and width for the bars (REQUIRED FOR PLOTTING MULTIPLE BARS FOR THE SAME VARIABLE)  \n",
    "positions = range(len(hourly_counts_per_threshold_df))\n",
    "\n",
    "# Plot each threshold as a separate set of bars\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    ax.bar([position + bar_width * i for position in positions], # Shifting the bars to allow plotting per threshold\n",
    "           hourly_counts_per_threshold_df[f'Count_{threshold}'], \n",
    "           width=0.2,\n",
    "           label=f'Count > {threshold}')\n",
    "\n",
    "# Set the x-ticks and labels\n",
    "ax.set_xticks([position + 0.2 * (len(thresholds) / 2 - 0.5) for position in positions]) ##TODO: improve this positioning\n",
    "ax.set_xticklabels(hourly_counts_per_threshold_df['Algorithm'])\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Algorithm')\n",
    "ax.set_ylabel('Count of Hours')\n",
    "ax.set_title(f'Count of Hours Above Thresholds {start_year}–{end_year}')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily mean level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_mean_heat_indeces_cubelist = iris.cube.CubeList([])\n",
    "for cube in heat_indeces_cubelist:\n",
    "    daily_mean = cube.aggregated_by(['year', 'day_of_year'], iris.analysis.MEAN)\n",
    "    daily_mean_heat_indeces_cubelist.append(daily_mean)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "daily_counts_per_threshold_df = pd.DataFrame(columns=['Algorithm'] + [f'Count_{threshold}' for threshold in thresholds])\n",
    "\n",
    "daily_counts_per_threshold_df['Algorithm'] = [cube.long_name for cube in heat_indeces_cubelist]\n",
    "daily_counts_per_threshold_df\n",
    "\n",
    "for i, cube in enumerate(daily_mean_heat_indeces_cubelist):\n",
    "    count_above_298 = (cube.data >= 298).sum()\n",
    "    daily_counts_per_threshold_df.loc[i, 'Count_298'] = count_above_298\n",
    "\n",
    "for i, cube in enumerate(daily_mean_heat_indeces_cubelist):\n",
    "    count_above_345 = (cube.data >= 345).sum()\n",
    "    daily_counts_per_threshold_df.loc[i, 'Count_345'] = count_above_345\n",
    "\n",
    "for i, cube in enumerate(daily_mean_heat_indeces_cubelist):\n",
    "    count_above_357 = (cube.data >= 357).sum()\n",
    "    daily_counts_per_threshold_df.loc[i, 'Count_357'] = count_above_357\n",
    "\n",
    "for i, cube in enumerate(daily_mean_heat_indeces_cubelist):\n",
    "    count_above_366 = (cube.data >= 366).sum()\n",
    "    daily_counts_per_threshold_df.loc[i, 'Count_366'] = count_above_366\n",
    "\n",
    "daily_counts_per_threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Days above threshold for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the thresholds\n",
    "# thresholds = [298, 345, 357, 366]\n",
    "\n",
    "# # Create an empty DataFrame to store the results\n",
    "# daily_counts_per_threshold_df = pd.DataFrame(columns=['Algorithm'] + [f'Count_{threshold}' for threshold in thresholds])\n",
    "\n",
    "# daily_counts_per_threshold_df['Algorithm'] = [cube.long_name for cube in heat_indeces_cubelist]\n",
    "\n",
    "\n",
    "# for i, cube in enumerate(heat_indeces_cubelist):\n",
    "#     count_above_298 = (cube.data > 298).sum()\n",
    "#     daily_counts_per_threshold_df.loc[i, 'Count_298'] = count_above_298\n",
    "\n",
    "# for i, cube in enumerate(heat_indeces_cubelist):\n",
    "#     count_above_345 = (cube.data > 345).sum()\n",
    "#     daily_counts_per_threshold_df.loc[i, 'Count_345'] = count_above_345\n",
    "\n",
    "# for i, cube in enumerate(heat_indeces_cubelist):\n",
    "#     count_above_357 = (cube.data > 357).sum()\n",
    "#     daily_counts_per_threshold_df.loc[i, 'Count_357'] = count_above_357\n",
    "\n",
    "# for i, cube in enumerate(heat_indeces_cubelist):\n",
    "#     count_above_366 = (cube.data > 366).sum()\n",
    "#     daily_counts_per_threshold_df.loc[i, 'Count_366'] = count_above_366\n",
    "\n",
    "# daily_counts_per_threshold_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic comparisons between heat index algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_yearly_mean_values_from_heat_indexes() # Plots the yearly mean values of the heat indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_of_differences_between_heat_index_and_air_temperature() # Creates a table of differences between heat index and air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_difference_from_air_temperature() # Plots the difference from air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_differences_from_Lu_and_Romps_for_each_index() # Plots the mean differences from Lu and Romps for each index\n",
    "print(\"REMEMBER! Lu and Romps is basically 0 anyway so the plots will look similar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_of_differences_between_heat_index_and_Lu_and_Romps() # Creates a table of differences between heat index and Lu and Romps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_index_comparison_maps() # Plots the heat index comparison maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_index_maps_relative_to_Lu_and_Romps() # Plots the heat index maps relative to Lu and Romps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_cubelist() # Normalises the cube list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_algorithms()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
